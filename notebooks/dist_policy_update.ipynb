{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How update CTA policy in distributed setting \n",
    "\n",
    "Original code does the following:\n",
    "```python\n",
    "    def update_cta_rates(self):\n",
    "        x, y, policies = self.state.batch[\"cta_probe_batch\"]\n",
    "        self.ema_model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.ema_model(x)\n",
    "            y_probas = torch.softmax(y_pred, dim=1)  # (N, C)\n",
    "\n",
    "            for y_proba, t, policy in zip(y_probas, y, policies):                \n",
    "                error = y_proba\n",
    "                error[t] -= 1\n",
    "                error = torch.abs(error).sum()\n",
    "                self.cta.update_rates(policy, 1.0 - 0.5 * error.item())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "cta = utils.get_default_cta()\n",
    "\n",
    "supervised_train_dataset = utils.get_supervised_trainset_0_250(\"/tmp/cifar10/\")\n",
    "\n",
    "cta_probe_loader = utils.get_cta_probe_loader(\n",
    "    supervised_train_dataset,\n",
    "    cta=cta,\n",
    "    batch_size=8,\n",
    "    num_workers=12,\n",
    "    sampler=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have WORLD_SIZE=2 and thus we have 2 batches for each rank. How we need to update CTA rates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cta_probe_loader_iter = iter(cta_probe_loader)\n",
    "cta_probe_batch_r1 = next(cta_probe_loader_iter)\n",
    "cta_probe_batch_r2 = next(cta_probe_loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1, policies1 = (\n",
    "    *utils.sup_prepare_batch(cta_probe_batch_r1, utils.device, non_blocking=True),\n",
    "    [utils.deserialize(p) for p in cta_probe_batch_r1['policy']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2, y2, policies2 = (\n",
    "    *utils.sup_prepare_batch(cta_probe_batch_r2, utils.device, non_blocking=True),\n",
    "    [utils.deserialize(p) for p in cta_probe_batch_r2['policy']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(policies1), len(policies2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[OP(f='translate_y', bins=[0.6284187969367999]),\n",
       "  OP(f='smooth', bins=[0.9300541326018598])],\n",
       " [OP(f='rescale', bins=[0.4410249998926222, 0.37404114665565613]),\n",
       "  OP(f='rescale', bins=[0.34877247031343983, 0.80745831615098])],\n",
       " [OP(f='autocontrast', bins=[0.9504645469663052]),\n",
       "  OP(f='brightness', bins=[0.5678519516876261])],\n",
       " [OP(f='invert', bins=[0.8041796089170575]), OP(f='identity', bins=[])],\n",
       " [OP(f='equalize', bins=[0.0017531965395323201]),\n",
       "  OP(f='translate_y', bins=[0.8608303540742768])],\n",
       " [OP(f='blur', bins=[0.9104848104507769]),\n",
       "  OP(f='posterize', bins=[0.31135027907028645])],\n",
       " [OP(f='shear_y', bins=[0.6413432131765835]),\n",
       "  OP(f='translate_x', bins=[0.6387265618124591])],\n",
       " [OP(f='translate_x', bins=[0.384357732892316]),\n",
       "  OP(f='invert', bins=[0.2567598188184105])]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[OP(f='autocontrast', bins=[0.6284187969367999]),\n",
       "  OP(f='brightness', bins=[0.9300541326018598])],\n",
       " [OP(f='shear_y', bins=[0.4410249998926222]),\n",
       "  OP(f='autocontrast', bins=[0.37404114665565613])],\n",
       " [OP(f='solarize', bins=[0.34877247031343983]),\n",
       "  OP(f='solarize', bins=[0.80745831615098])],\n",
       " [OP(f='shear_x', bins=[0.9504645469663052]),\n",
       "  OP(f='rescale', bins=[0.5678519516876261, 0.8041796089170575])],\n",
       " [OP(f='invert', bins=[0.0017531965395323201]),\n",
       "  OP(f='shear_x', bins=[0.8608303540742768])],\n",
       " [OP(f='shear_y', bins=[0.9104848104507769]),\n",
       "  OP(f='solarize', bins=[0.31135027907028645])],\n",
       " [OP(f='translate_x', bins=[0.6413432131765835]),\n",
       "  OP(f='brightness', bins=[0.6387265618124591])],\n",
       " [OP(f='brightness', bins=[0.384357732892316]),\n",
       "  OP(f='solarize', bins=[0.2567598188184105])]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store `error_per_op` as a list of packed `(op name index, num_bins, bins, error, [PAD], ..., [PAD])` for each rank. Gather all tensors `error_per_op` into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ctaugment import OPS\n",
    "\n",
    "\n",
    "sorted_op_names = sorted(list(OPS.keys()))\n",
    "\n",
    "\n",
    "def pack_as_tensor(k, bins, error, size=5, pad_value=-555.0):\n",
    "    out = torch.empty(size).fill_(pad_value).to(error)\n",
    "    out[0] = sorted_op_names.index(k)\n",
    "    le = len(bins)\n",
    "    out[1] = le\n",
    "    out[2:2 + le] = torch.tensor(bins).to(error)\n",
    "    out[2 + le] = error\n",
    "    return out\n",
    "\n",
    "\n",
    "def unpack_from_tensor(t):\n",
    "    k_index = int(t[0].item())\n",
    "    le = int(t[1].item())\n",
    "    bins = t[2:2 + le].tolist()\n",
    "    error = t[2 + le].item()\n",
    "    return sorted_op_names[k_index], bins, error\n",
    "    \n",
    "\n",
    "def get_error_per_op(policies):\n",
    "    error_per_op = []\n",
    "    y_probas = torch.rand(len(policies), 10).to(utils.device)\n",
    "    y = torch.randint(0, 10, size=(len(policies), )).to(utils.device)\n",
    "    for y_proba, t, policy in zip(y_probas, y, policies):\n",
    "        error = y_proba\n",
    "        error[t] -= 1\n",
    "        error = torch.abs(error).sum()\n",
    "        for k, bins in policy:            \n",
    "            error_per_op.append(pack_as_tensor(k, bins, error))\n",
    "    return torch.stack(error_per_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_per_op_r1 = get_error_per_op(policies1)\n",
    "error_per_op_r2 = get_error_per_op(policies2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8000e+01,  1.0000e+00,  6.2842e-01,  7.1072e+00, -5.5500e+02],\n",
       "        [ 1.5000e+01,  1.0000e+00,  9.3005e-01,  7.1072e+00, -5.5500e+02],\n",
       "        [ 1.0000e+01,  2.0000e+00,  4.4102e-01,  3.7404e-01,  4.4467e+00],\n",
       "        [ 1.0000e+01,  2.0000e+00,  3.4877e-01,  8.0746e-01,  4.4467e+00],\n",
       "        [ 0.0000e+00,  1.0000e+00,  9.5046e-01,  5.6430e+00, -5.5500e+02],\n",
       "        [ 2.0000e+00,  1.0000e+00,  5.6785e-01,  5.6430e+00, -5.5500e+02],\n",
       "        [ 8.0000e+00,  1.0000e+00,  8.0418e-01,  5.0689e+00, -5.5500e+02],\n",
       "        [ 7.0000e+00,  0.0000e+00,  5.0689e+00, -5.5500e+02, -5.5500e+02],\n",
       "        [ 6.0000e+00,  1.0000e+00,  1.7532e-03,  4.8191e+00, -5.5500e+02],\n",
       "        [ 1.8000e+01,  1.0000e+00,  8.6083e-01,  4.8191e+00, -5.5500e+02],\n",
       "        [ 1.0000e+00,  1.0000e+00,  9.1048e-01,  4.3740e+00, -5.5500e+02],\n",
       "        [ 9.0000e+00,  1.0000e+00,  3.1135e-01,  4.3740e+00, -5.5500e+02],\n",
       "        [ 1.4000e+01,  1.0000e+00,  6.4134e-01,  5.5784e+00, -5.5500e+02],\n",
       "        [ 1.7000e+01,  1.0000e+00,  6.3873e-01,  5.5784e+00, -5.5500e+02],\n",
       "        [ 1.7000e+01,  1.0000e+00,  3.8436e-01,  5.8519e+00, -5.5500e+02],\n",
       "        [ 8.0000e+00,  1.0000e+00,  2.5676e-01,  5.8519e+00, -5.5500e+02]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_per_op_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('translate_y', [0.6284188032150269], 7.1072211265563965)\n",
      "('smooth', [0.9300541281700134], 7.1072211265563965)\n",
      "('rescale', [0.4410249888896942, 0.3740411400794983], 4.44674825668335)\n",
      "('rescale', [0.34877246618270874, 0.8074583411216736], 4.44674825668335)\n",
      "('autocontrast', [0.9504645466804504], 5.643031120300293)\n",
      "('brightness', [0.5678519606590271], 5.643031120300293)\n",
      "('invert', [0.8041796088218689], 5.068888187408447)\n",
      "('identity', [], 5.068888187408447)\n",
      "('equalize', [0.0017531965859234333], 4.819091796875)\n",
      "('translate_y', [0.8608303666114807], 4.819091796875)\n",
      "('blur', [0.910484790802002], 4.374037742614746)\n",
      "('posterize', [0.3113502860069275], 4.374037742614746)\n",
      "('shear_y', [0.6413432359695435], 5.578389644622803)\n",
      "('translate_x', [0.638726532459259], 5.578389644622803)\n",
      "('translate_x', [0.3843577206134796], 5.851930141448975)\n",
      "('invert', [0.2567598223686218], 5.851930141448975)\n"
     ]
    }
   ],
   "source": [
    "for t in error_per_op_r1:\n",
    "    print(unpack_from_tensor(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.0000e+00,  6.2842e-01,  5.3517e+00, -5.5500e+02],\n",
       "        [ 2.0000e+00,  1.0000e+00,  9.3005e-01,  5.3517e+00, -5.5500e+02],\n",
       "        [ 1.4000e+01,  1.0000e+00,  4.4102e-01,  5.9118e+00, -5.5500e+02],\n",
       "        [ 0.0000e+00,  1.0000e+00,  3.7404e-01,  5.9118e+00, -5.5500e+02],\n",
       "        [ 1.6000e+01,  1.0000e+00,  3.4877e-01,  3.3680e+00, -5.5500e+02],\n",
       "        [ 1.6000e+01,  1.0000e+00,  8.0746e-01,  3.3680e+00, -5.5500e+02],\n",
       "        [ 1.3000e+01,  1.0000e+00,  9.5046e-01,  5.4213e+00, -5.5500e+02],\n",
       "        [ 1.0000e+01,  2.0000e+00,  5.6785e-01,  8.0418e-01,  5.4213e+00],\n",
       "        [ 8.0000e+00,  1.0000e+00,  1.7532e-03,  6.0290e+00, -5.5500e+02],\n",
       "        [ 1.3000e+01,  1.0000e+00,  8.6083e-01,  6.0290e+00, -5.5500e+02],\n",
       "        [ 1.4000e+01,  1.0000e+00,  9.1048e-01,  6.6215e+00, -5.5500e+02],\n",
       "        [ 1.6000e+01,  1.0000e+00,  3.1135e-01,  6.6215e+00, -5.5500e+02],\n",
       "        [ 1.7000e+01,  1.0000e+00,  6.4134e-01,  4.7493e+00, -5.5500e+02],\n",
       "        [ 2.0000e+00,  1.0000e+00,  6.3873e-01,  4.7493e+00, -5.5500e+02],\n",
       "        [ 2.0000e+00,  1.0000e+00,  3.8436e-01,  5.8040e+00, -5.5500e+02],\n",
       "        [ 1.6000e+01,  1.0000e+00,  2.5676e-01,  5.8040e+00, -5.5500e+02]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_per_op_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OP(f='autocontrast', bins=[0.5619854072623901]),\n",
       " OP(f='blur', bins=[0.7046307087372261]),\n",
       " OP(f='brightness', bins=[0.9352483842108498]),\n",
       " OP(f='color', bins=[0.39131998433592863]),\n",
       " OP(f='contrast', bins=[0.7128734752302066]),\n",
       " OP(f='cutout', bins=[0.3314181264088959]),\n",
       " OP(f='equalize', bins=[0.7093151749948137]),\n",
       " OP(f='invert', bins=[0.5623374776059373]),\n",
       " OP(f='identity', bins=[]),\n",
       " OP(f='posterize', bins=[0.9360352729278023]),\n",
       " OP(f='rescale', bins=[0.49353615762657277, 0.1656012491615455]),\n",
       " OP(f='rotate', bins=[0.2959720097201758]),\n",
       " OP(f='sharpness', bins=[0.2117442040912716]),\n",
       " OP(f='shear_x', bins=[0.02576970813472279]),\n",
       " OP(f='shear_y', bins=[0.44570923815749397]),\n",
       " OP(f='smooth', bins=[0.49317636039863744]),\n",
       " OP(f='solarize', bins=[0.4949358331955145]),\n",
       " OP(f='translate_x', bins=[0.4352882706872071]),\n",
       " OP(f='translate_y', bins=[0.48944830740684386])]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "kl = list(OPS.keys())\n",
    "all_policy_ops = []\n",
    "for k in kl:\n",
    "    bins = cta.rates[k]\n",
    "    rnd = np.random.uniform(0, 1, len(bins))\n",
    "    all_policy_ops.append(OP(k, rnd.tolist()))\n",
    "all_policy_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, bins in all_policy_ops:\n",
    "    error = torch.rand(1)\n",
    "    # check pack_as_tensor / unpack_from_tensor\n",
    "    t = pack_as_tensor(k, bins, error)\n",
    "    new_k, new_bins, new_error = unpack_from_tensor(t)\n",
    "    assert new_k == k, \"{} vs {}\".format(new_k, k)\n",
    "    assert all([abs(v1 - v2) < 1e-7 for v1, v2 in zip(new_bins, bins)]), \"{} vs {}\".format(new_bins, bins)\n",
    "    assert new_error == error.item(), \"{} vs {}\".format(new_error, error.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_list = [\n",
    "#     torch.empty_like(error_per_op) \n",
    "#     for _ in range(dist.get_world_size())\n",
    "# ]\n",
    "# dist.all_gather(tensor_list, error_per_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.8000e+01,  1.0000e+00,  6.2842e-01,  7.1072e+00, -5.5500e+02],\n",
       "         [ 1.5000e+01,  1.0000e+00,  9.3005e-01,  7.1072e+00, -5.5500e+02],\n",
       "         [ 1.0000e+01,  2.0000e+00,  4.4102e-01,  3.7404e-01,  4.4467e+00],\n",
       "         [ 1.0000e+01,  2.0000e+00,  3.4877e-01,  8.0746e-01,  4.4467e+00],\n",
       "         [ 0.0000e+00,  1.0000e+00,  9.5046e-01,  5.6430e+00, -5.5500e+02],\n",
       "         [ 2.0000e+00,  1.0000e+00,  5.6785e-01,  5.6430e+00, -5.5500e+02],\n",
       "         [ 8.0000e+00,  1.0000e+00,  8.0418e-01,  5.0689e+00, -5.5500e+02],\n",
       "         [ 7.0000e+00,  0.0000e+00,  5.0689e+00, -5.5500e+02, -5.5500e+02],\n",
       "         [ 6.0000e+00,  1.0000e+00,  1.7532e-03,  4.8191e+00, -5.5500e+02],\n",
       "         [ 1.8000e+01,  1.0000e+00,  8.6083e-01,  4.8191e+00, -5.5500e+02],\n",
       "         [ 1.0000e+00,  1.0000e+00,  9.1048e-01,  4.3740e+00, -5.5500e+02],\n",
       "         [ 9.0000e+00,  1.0000e+00,  3.1135e-01,  4.3740e+00, -5.5500e+02],\n",
       "         [ 1.4000e+01,  1.0000e+00,  6.4134e-01,  5.5784e+00, -5.5500e+02],\n",
       "         [ 1.7000e+01,  1.0000e+00,  6.3873e-01,  5.5784e+00, -5.5500e+02],\n",
       "         [ 1.7000e+01,  1.0000e+00,  3.8436e-01,  5.8519e+00, -5.5500e+02],\n",
       "         [ 8.0000e+00,  1.0000e+00,  2.5676e-01,  5.8519e+00, -5.5500e+02]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0000e+00,  1.0000e+00,  6.2842e-01,  5.3517e+00, -5.5500e+02],\n",
       "         [ 2.0000e+00,  1.0000e+00,  9.3005e-01,  5.3517e+00, -5.5500e+02],\n",
       "         [ 1.4000e+01,  1.0000e+00,  4.4102e-01,  5.9118e+00, -5.5500e+02],\n",
       "         [ 0.0000e+00,  1.0000e+00,  3.7404e-01,  5.9118e+00, -5.5500e+02],\n",
       "         [ 1.6000e+01,  1.0000e+00,  3.4877e-01,  3.3680e+00, -5.5500e+02],\n",
       "         [ 1.6000e+01,  1.0000e+00,  8.0746e-01,  3.3680e+00, -5.5500e+02],\n",
       "         [ 1.3000e+01,  1.0000e+00,  9.5046e-01,  5.4213e+00, -5.5500e+02],\n",
       "         [ 1.0000e+01,  2.0000e+00,  5.6785e-01,  8.0418e-01,  5.4213e+00],\n",
       "         [ 8.0000e+00,  1.0000e+00,  1.7532e-03,  6.0290e+00, -5.5500e+02],\n",
       "         [ 1.3000e+01,  1.0000e+00,  8.6083e-01,  6.0290e+00, -5.5500e+02],\n",
       "         [ 1.4000e+01,  1.0000e+00,  9.1048e-01,  6.6215e+00, -5.5500e+02],\n",
       "         [ 1.6000e+01,  1.0000e+00,  3.1135e-01,  6.6215e+00, -5.5500e+02],\n",
       "         [ 1.7000e+01,  1.0000e+00,  6.4134e-01,  4.7493e+00, -5.5500e+02],\n",
       "         [ 2.0000e+00,  1.0000e+00,  6.3873e-01,  4.7493e+00, -5.5500e+02],\n",
       "         [ 2.0000e+00,  1.0000e+00,  3.8436e-01,  5.8040e+00, -5.5500e+02],\n",
       "         [ 1.6000e+01,  1.0000e+00,  2.5676e-01,  5.8040e+00, -5.5500e+02]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_list = [error_per_op_r1, error_per_op_r2]\n",
    "tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list = torch.cat(tensor_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8000e+01,  1.0000e+00,  6.2842e-01,  7.1072e+00, -5.5500e+02],\n",
       "        [ 1.5000e+01,  1.0000e+00,  9.3005e-01,  7.1072e+00, -5.5500e+02],\n",
       "        [ 1.0000e+01,  2.0000e+00,  4.4102e-01,  3.7404e-01,  4.4467e+00],\n",
       "        [ 1.0000e+01,  2.0000e+00,  3.4877e-01,  8.0746e-01,  4.4467e+00],\n",
       "        [ 0.0000e+00,  1.0000e+00,  9.5046e-01,  5.6430e+00, -5.5500e+02],\n",
       "        [ 2.0000e+00,  1.0000e+00,  5.6785e-01,  5.6430e+00, -5.5500e+02],\n",
       "        [ 8.0000e+00,  1.0000e+00,  8.0418e-01,  5.0689e+00, -5.5500e+02],\n",
       "        [ 7.0000e+00,  0.0000e+00,  5.0689e+00, -5.5500e+02, -5.5500e+02],\n",
       "        [ 6.0000e+00,  1.0000e+00,  1.7532e-03,  4.8191e+00, -5.5500e+02],\n",
       "        [ 1.8000e+01,  1.0000e+00,  8.6083e-01,  4.8191e+00, -5.5500e+02],\n",
       "        [ 1.0000e+00,  1.0000e+00,  9.1048e-01,  4.3740e+00, -5.5500e+02],\n",
       "        [ 9.0000e+00,  1.0000e+00,  3.1135e-01,  4.3740e+00, -5.5500e+02],\n",
       "        [ 1.4000e+01,  1.0000e+00,  6.4134e-01,  5.5784e+00, -5.5500e+02],\n",
       "        [ 1.7000e+01,  1.0000e+00,  6.3873e-01,  5.5784e+00, -5.5500e+02],\n",
       "        [ 1.7000e+01,  1.0000e+00,  3.8436e-01,  5.8519e+00, -5.5500e+02],\n",
       "        [ 8.0000e+00,  1.0000e+00,  2.5676e-01,  5.8519e+00, -5.5500e+02],\n",
       "        [ 0.0000e+00,  1.0000e+00,  6.2842e-01,  5.3517e+00, -5.5500e+02],\n",
       "        [ 2.0000e+00,  1.0000e+00,  9.3005e-01,  5.3517e+00, -5.5500e+02],\n",
       "        [ 1.4000e+01,  1.0000e+00,  4.4102e-01,  5.9118e+00, -5.5500e+02],\n",
       "        [ 0.0000e+00,  1.0000e+00,  3.7404e-01,  5.9118e+00, -5.5500e+02],\n",
       "        [ 1.6000e+01,  1.0000e+00,  3.4877e-01,  3.3680e+00, -5.5500e+02],\n",
       "        [ 1.6000e+01,  1.0000e+00,  8.0746e-01,  3.3680e+00, -5.5500e+02],\n",
       "        [ 1.3000e+01,  1.0000e+00,  9.5046e-01,  5.4213e+00, -5.5500e+02],\n",
       "        [ 1.0000e+01,  2.0000e+00,  5.6785e-01,  8.0418e-01,  5.4213e+00],\n",
       "        [ 8.0000e+00,  1.0000e+00,  1.7532e-03,  6.0290e+00, -5.5500e+02],\n",
       "        [ 1.3000e+01,  1.0000e+00,  8.6083e-01,  6.0290e+00, -5.5500e+02],\n",
       "        [ 1.4000e+01,  1.0000e+00,  9.1048e-01,  6.6215e+00, -5.5500e+02],\n",
       "        [ 1.6000e+01,  1.0000e+00,  3.1135e-01,  6.6215e+00, -5.5500e+02],\n",
       "        [ 1.7000e+01,  1.0000e+00,  6.4134e-01,  4.7493e+00, -5.5500e+02],\n",
       "        [ 2.0000e+00,  1.0000e+00,  6.3873e-01,  4.7493e+00, -5.5500e+02],\n",
       "        [ 2.0000e+00,  1.0000e+00,  3.8436e-01,  5.8040e+00, -5.5500e+02],\n",
       "        [ 1.6000e+01,  1.0000e+00,  2.5676e-01,  5.8040e+00, -5.5500e+02]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('translate_y', [0.6284188032150269], 7.1072211265563965)\n",
      "('smooth', [0.9300541281700134], 7.1072211265563965)\n",
      "('rescale', [0.4410249888896942, 0.3740411400794983], 4.44674825668335)\n",
      "('rescale', [0.34877246618270874, 0.8074583411216736], 4.44674825668335)\n",
      "('autocontrast', [0.9504645466804504], 5.643031120300293)\n",
      "('brightness', [0.5678519606590271], 5.643031120300293)\n",
      "('invert', [0.8041796088218689], 5.068888187408447)\n",
      "('identity', [], 5.068888187408447)\n",
      "('equalize', [0.0017531965859234333], 4.819091796875)\n",
      "('translate_y', [0.8608303666114807], 4.819091796875)\n",
      "('blur', [0.910484790802002], 4.374037742614746)\n",
      "('posterize', [0.3113502860069275], 4.374037742614746)\n",
      "('shear_y', [0.6413432359695435], 5.578389644622803)\n",
      "('translate_x', [0.638726532459259], 5.578389644622803)\n",
      "('translate_x', [0.3843577206134796], 5.851930141448975)\n",
      "('invert', [0.2567598223686218], 5.851930141448975)\n",
      "('autocontrast', [0.6284188032150269], 5.351713180541992)\n",
      "('brightness', [0.9300541281700134], 5.351713180541992)\n",
      "('shear_y', [0.4410249888896942], 5.911818504333496)\n",
      "('autocontrast', [0.3740411400794983], 5.911818504333496)\n",
      "('solarize', [0.34877246618270874], 3.3679685592651367)\n",
      "('solarize', [0.8074583411216736], 3.3679685592651367)\n",
      "('shear_x', [0.9504645466804504], 5.421313285827637)\n",
      "('rescale', [0.5678519606590271, 0.8041796088218689], 5.421313285827637)\n",
      "('invert', [0.0017531965859234333], 6.028983116149902)\n",
      "('shear_x', [0.8608303666114807], 6.028983116149902)\n",
      "('shear_y', [0.910484790802002], 6.621496677398682)\n",
      "('solarize', [0.3113502860069275], 6.621496677398682)\n",
      "('translate_x', [0.6413432359695435], 4.749312400817871)\n",
      "('brightness', [0.638726532459259], 4.749312400817871)\n",
      "('brightness', [0.3843577206134796], 5.804039001464844)\n",
      "('solarize', [0.2567598223686218], 5.804039001464844)\n"
     ]
    }
   ],
   "source": [
    "for t in tensor_list:\n",
    "    print(unpack_from_tensor(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
